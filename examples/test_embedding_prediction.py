import os
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from gpbacay_arcane.mechanisms import ResonantGSERCell

def prove_embedding_prediction():
    print("=== Proving Embedding Space Prediction in ResonantGSER ===")
    
    # 1. Setup parameters
    units = 128
    input_dim = 64
    resonance_cycles = 10  # We'll use more cycles to see the convergence curve
    
    # 2. Instantiate the ResonantGSERCell
    cell = ResonantGSERCell(
        units=units, 
        resonance_factor=0.2, 
        resonance_cycles=resonance_cycles,
        convergence_epsilon=1e-7
    )
    
    # Build the cell
    cell.build((None, input_dim))
    
    # 3. Create dummy input and initial states
    inputs = tf.random.normal((1, input_dim))
    initial_states = cell.get_initial_state(inputs=inputs)
    
    # 4. Create a "Top-Down Projection" (The latent-space target)
    # In a real model, this would come from a higher layer
    target_latent_state = tf.random.normal((1, units))
    
    # Set the projection alignment target in the cell
    cell.resonance_alignment.assign(tf.squeeze(target_latent_state))
    
    # 5. Manually run the Resonance Loop and track divergence
    # We will step through cycles one by one to record the physics of the embedding space
    h_current, _ = cell.lstm_cell(inputs, initial_states) # Step 1: Forward Initialization
    
    divergence_history = []
    
    print(f"\nTargeting Latent Point (Embedding Target)...")
    
    for cycle in range(resonance_cycles):
        # Compute divergence (distance in embedding space)
        delta = cell.compute_divergence(h_current, target_latent_state)
        dist = tf.reduce_mean(tf.square(delta)).numpy()
        divergence_history.append(dist)
        
        print(f"Cycle {cycle+1}: Global Divergence (L2 Distance) = {dist:.8f}")
        
        # Harmonize (Move the state in embedding space)
        h_current = cell.harmonize_state(h_current, delta, cell.resonance_factor)

    # 6. Analysis
    print("\n=== Analysis ===")
    initial_div = divergence_history[0]
    final_div = divergence_history[-1]
    reduction = (initial_div - final_div) / initial_div * 100
    
    print(f"Initial State Distance: {initial_div:.6f}")
    print(f"Final Aligned Distance: {final_div:.6f}")
    print(f"Total Divergence Reduction: {reduction:.2f}%")
    
    if final_div < initial_div:
        print("\nSUCCESS: The ResonantGSER performs Latent-Space Alignment.")
        print("This proves the model optimizes 'Meanings' (Embeddings) via deliberation,")
        print("moving the internal representation toward a predicted target BEFORE generating tokens.")
    else:
        print("\nFAILURE: State did not converge.")

    # 7. Visualization
    plt.figure(figsize=(10, 5))
    plt.plot(range(1, resonance_cycles + 1), divergence_history, marker='o', color='#00ffcc', linewidth=2)
    plt.title("Convergence to Latent-Space Prediction (RSAA Cycle)", color='white')
    plt.xlabel("Resonance Cycle", color='white')
    plt.ylabel("Prediction Divergence (Î”)", color='white')
    plt.grid(True, alpha=0.3)
    plt.gca().set_facecolor('#1e1e1e')
    plt.gcf().set_facecolor('#121212')
    plt.tick_params(colors='white')
    
    # Save the proof
    output_path = "resonance_convergence_proof.png"
    plt.savefig(output_path)
    print(f"\nProof visualization saved to: {output_path}")

if __name__ == "__main__":
    prove_embedding_prediction()
